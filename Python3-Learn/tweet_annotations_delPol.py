# -*- coding: utf-8 -*-
"""psosm3data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16Rh7oQWNQsKR9omQfbxNoR4U4X8uhdMG
"""

!pip install twint
!pip install pandas
import pickle
import twint
import pandas as pd

import twint
import pickle

# Configure
c = twint.Config()
k=twint.Config()
m=twint.Config()
# c.Username = "now"
c.Search = "(@DelhiPolice OR @CPDelhi OR @dtpdelhi OR @DCPNewDelhi OR @DCPCentralDelhi) AND (janpath)"
c.Lang = "en"
c.Since="2019-12-01"
c.Until= "2020-03-07"
c.Store_object = True
# Run
twint.run.Search(c)
tweets_janpath = twint.output.tweets_list
output = open('janpath_tweets.pkl', 'wb')
pickle.dump(tweets_janpath,output)

k.Search = "(@DelhiPolice OR @CPDelhi OR @dtpdelhi OR @DCPNewDelhi OR @DCPCentralDelhi) AND (mandi house)"
k.Lang = "en"
k.Since="2019-12-01"
k.Until= "2020-03-07"
k.Store_object = True
twint.run.Search(k)
tweets_mandi_house = twint.output.tweets_list
output1 = open('mandi_house_tweets.pkl', 'wb')
pickle.dump(tweets_mandi_house,output1)

f = open('mandi_house_tweets.pkl', 'rb')
x = pickle.load(f)
print((tweets_mandi_house[0].tweet))

m.Search = "(@DelhiPolice OR @CPDelhi OR @dtpdelhi OR @DCPNewDelhi OR @DCPCentralDelhi) AND (jaffrabad)"
m.Lang = "en"
m.Since="2019-12-01"
m.Until= "2020-03-07"
m.Store_object = True
twint.run.Search(m)
tweets_jaffrabad = twint.output.tweets_list
output = open('jaffrabad.pkl', 'wb')
pickle.dump(tweets_jaffrabad,output)

import pickle
output = open('mandi_house.pkl', 'wb')
pickle.dump(tweets_mandi_house,output)
output = open('janpath.pkl', 'wb')
pickle.dump(tweets_janpath,output)
output = open('jaffrabad.pkl', 'wb')
pickle.dump(tweets_jaffrabad,output)

from google.colab import files
# files.download('mandi_house.pkl')
# # files.download('janpath.pkl')
# files.download('jaffrabad.pkl')

from google.colab import drive
drive.mount('/content/drive')

import pickle 
neha=open('/content/drive/My Drive/psosm A3 data/annotateneha_tweets.pkl','rb')
bharath=open('/content/drive/My Drive/psosm A3 data/annotatebharath_tweets.pkl','rb')
raunak=open('/content/drive/My Drive/psosm A3 data/annotateraunak_tweets.pkl','rb')

neha_ann= pickle.load(neha)
bharath_ann=pickle.load(bharath)
raunak_ann=pickle.load(raunak)
bharath_ann.extend(neha_ann)
bharath_ann.extend(raunak_ann)
tweets_all=bharath_ann
print(len(tweets_all))
count = 1
for twNum in bharath_ann:
  print(count, twNum)
  print()
  print()

print(dir(bharath_ann[2][0]))

import tweepy
import datetime
auth = tweepy.OAuthHandler('zMAhIC7tltCeADqMlccfyEMOq', 
                            '9azbYvDJodD2abUmt7Ko87fqNDaNEIqhrfixIFWmSO9JXhlABi')

auth.set_access_token('1214420430435405824-KhLncq8hnA2nX1B37RTdY35g2CcVdk', 
                        'haekdJOgu6khvJLqaUFPrfqnwoMTOjVh5EkGyzya6t0Nl')
api = tweepy.API(auth, wait_on_rate_limit=True)
def get_user_details(username):
  user=api.get_user(username)
  verified=user.verified
  followers_count=user.followers_count
  friends_count=user.friends_count
  num_tweets=user.statuses_count
  return verified,followers_count,friends_count,num_tweets

import re
def remove_hash(hashtag):
  hashtags=[]
  for i in hashtag:
    hashtags.append(i[1:])
  return hashtags
def find_email(text):
  email = x=re.findall('[\w\.-]+@[\w\.-]+\.\w+',text) 
  if email==[]:
    return None
  return email 
  
def find_phone(text):
  phone = x=re.findall('\+?\d[\d -]{8,12}\d',text) 
  if phone==[]:
    return None
  return phone

df=pd.DataFrame(columns=['id','tweet_text','emails','date','timezone','num_date', 'links', 'phone_numbers', 'username', 'hashtags', 'location','mentioned_names','is_retweet','anotations','car_number','user_verified','followers', 'followees', 'num_of_tweets'])
print(len(df.index))
for j,i in enumerate(tweets_all):
  k=i[1]
  i=i[0]
  hashtags=remove_hash(i.hashtags)
  email=find_email(i.tweet)
  phone=find_phone(i.tweet)
  a,b,c,d=get_user_details(i.username)
  row=[i.id,i.tweet,email,i.datestamp,i.timezone,i.datetime,i.urls,phone,i.username,hashtags,None,i.mentions,i.retweet,k,None,a,b,c,d]
  df.loc[j]=row
print(df.head)

print(df.loc[0])

from google.colab import files
df.to_csv('/content/drive/My Drive/psosm A3 data/data_psosm.csv')
files.download('data_psosm.csv')